{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5HnLghpw0Iaz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from scipy.spatial import distance\n",
        "import numpy as np\n",
        "import arviz as az\n",
        "import xarray as xr\n",
        "import pystan\n",
        "import nest_asyncio\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SGqUO65R0f6t"
      },
      "outputs": [],
      "source": [
        "shapefile_path = '/content/drive/MyDrive/stat836-final-project/neighborhoods'\n",
        "sf_neighborhoods = gpd.read_file(shapefile_path)\n",
        "\n",
        "# SF case and population data\n",
        "sf_cases = pd.read_csv('/content/drive/MyDrive/stat836-final-project/master_merged.csv', index_col=False)\n",
        "sf_cases.rename(columns={'Neighborhood': 'nhood'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A3IwAdK1Mky",
        "outputId": "53640fed-63fc-4eab-de7c-069ef765739b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 1, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 1]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sf_cases = sf_cases.drop(41)\n",
        "\n",
        "# Calculating distance matrix\n",
        "sf_neighborhoods_projected = sf_neighborhoods.to_crs(epsg=32610)\n",
        "sf_neighborhoods_projected['centroid'] = sf_neighborhoods_projected.geometry.centroid\n",
        "\n",
        "neighborhood_x = sf_neighborhoods_projected['centroid'].geometry.x\n",
        "neighborhood_y = sf_neighborhoods_projected['centroid'].geometry.y\n",
        "\n",
        "neighborhood_xy = np.column_stack((neighborhood_x, neighborhood_y))\n",
        "\n",
        "distance_matrix = distance.cdist(neighborhood_xy, neighborhood_xy, 'euclidean')\n",
        "distance_matrix /=  1000.0\n",
        "\n",
        "# Compute weight matrix based off of if they are under 20% quantile\n",
        "quantile_20 = np.quantile(distance_matrix, 0.2)\n",
        "weight_matix = (distance_matrix < quantile_20).astype(int)\n",
        "weight_matix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UznY0uI2FJV",
        "outputId": "49e309a5-3542-4f4d-ad16-cde5d8db007a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     1238.0\n",
              "1      101.0\n",
              "2       13.0\n",
              "3        2.0\n",
              "4     4339.0\n",
              "5        2.0\n",
              "6      359.0\n",
              "7        2.0\n",
              "8      437.0\n",
              "9      118.0\n",
              "10     131.0\n",
              "11     243.0\n",
              "12     263.0\n",
              "13     417.0\n",
              "14      78.0\n",
              "15     139.0\n",
              "16     130.0\n",
              "17     185.0\n",
              "18       6.0\n",
              "19       2.0\n",
              "20      79.0\n",
              "21     369.0\n",
              "22    2625.0\n",
              "23      86.0\n",
              "24     434.0\n",
              "25      51.0\n",
              "26    2047.0\n",
              "27       2.0\n",
              "28      44.0\n",
              "29     125.0\n",
              "30    1163.0\n",
              "31     312.0\n",
              "32     756.0\n",
              "33     397.0\n",
              "34      45.0\n",
              "35       2.0\n",
              "36      66.0\n",
              "37      83.0\n",
              "38     620.0\n",
              "39     287.0\n",
              "40     619.0\n",
              "Name: Homeless Cases, dtype: float64"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sf_neighborhoods = pd.merge(sf_neighborhoods, sf_cases, on = 'nhood', how = 'left')\n",
        "\n",
        "sf_neighborhoods['Homeless Cases'] = sf_neighborhoods['Homeless Cases'].replace(0,2)\n",
        "sf_neighborhoods['Homeless Cases']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "clJxSDpx2iD3"
      },
      "outputs": [],
      "source": [
        "SF_code = \"\"\"\n",
        "data {\n",
        "    int n;\n",
        "    int y[n];\n",
        "    vector[n] logEi;\n",
        "    vector<lower=0>[n] income;\n",
        "    vector<lower=0>[n] homevalue;\n",
        "    vector<lower=0>[n] poverty;\n",
        "    vector<lower=0>[n] unemployed;\n",
        "    vector<lower=0>[n] education;\n",
        "    matrix<lower=0>[n,n] wmat;\n",
        "}\n",
        "parameters {\n",
        "    vector[n] theta;\n",
        "    vector[n] u;\n",
        "    real beta1;\n",
        "    real beta3;\n",
        "    real beta4;\n",
        "    real beta5;\n",
        "    real beta6;\n",
        "    real<lower=0> sigma2_u;\n",
        "    real<lower=0> sigma2_v;\n",
        "    real<lower=0> lambda;\n",
        "}\n",
        "model {\n",
        "    lambda ~ gamma(2, 1);\n",
        "    sigma2_u ~ inv_gamma(0.0005, 0.5);\n",
        "    sigma2_v ~ inv_gamma(0.0005, 0.5);\n",
        "    beta1 ~ double_exponential(0, lambda);\n",
        "    beta3 ~ double_exponential(0, lambda);\n",
        "    beta4 ~ double_exponential(0, lambda);\n",
        "    beta5 ~ double_exponential(0, lambda);\n",
        "    beta6 ~ double_exponential(0, lambda);\n",
        "\n",
        "    target += -0.5 * n * log(sigma2_u);\n",
        "    for (i in 1:n) {\n",
        "        for (j in 1:n) {\n",
        "            target += -0.5 * (u[i] - u[j])^2 * wmat[i, j] / sigma2_u;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for (i in 1:n) {\n",
        "        theta[i] ~ normal(logEi[i] + beta1 * income[i] + beta3 * homevalue[i] + beta4 * poverty[i] + beta5 * unemployed[i] + beta6 * education[i] + u[i], sqrt(sigma2_v));\n",
        "        y[i] ~ poisson(exp(theta[i]));\n",
        "    }\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YuMZzbvt2KDp"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    'n': 41,\n",
        "    'y': np.array(sf_neighborhoods['Homeless Cases']).astype(int).tolist(),\n",
        "    'logEi': sf_neighborhoods['Log Expected Cases'].tolist(),\n",
        "    'income': sf_neighborhoods['Median Household Income'].tolist(),\n",
        "    #'foreign': sf_neighborhoods['Foreign Born'].tolist(),\n",
        "    'homevalue': sf_neighborhoods['Median Home Value'].tolist(),\n",
        "    'poverty': sf_neighborhoods['Percent in Poverty'].tolist(),\n",
        "    'unemployed': sf_neighborhoods['A_Unemployment Rate'].tolist(),\n",
        "    'education': sf_neighborhoods['Bachelor\\'s degree or higher'].tolist(),\n",
        "    'wmat': weight_matix.tolist()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KQImRlu33oUg"
      },
      "outputs": [],
      "source": [
        "sm = pystan.StanModel(model_code=SF_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw2bqNdr5sl0"
      },
      "outputs": [],
      "source": [
        "fit = sm.sampling(data=data, chains=1, iter=20000, warmup=7500, control={'max_treedepth': 14, 'adapt_delta': 0.95})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4WeCdylo24v"
      },
      "outputs": [],
      "source": [
        "idata = az.from_pystan(fit)\n",
        "\n",
        "az.plot_trace(idata, var_names=['theta'])\n",
        "plt.show()\n",
        "\n",
        "az.plot_trace(idata, var_names=['beta1'])\n",
        "plt.show()\n",
        "\n",
        "az.plot_trace(idata, var_names=['beta3'])\n",
        "plt.show()\n",
        "\n",
        "az.plot_trace(idata, var_names=['beta4'])\n",
        "plt.show()\n",
        "\n",
        "az.plot_trace(idata, var_names=['beta5'])\n",
        "plt.show()\n",
        "\n",
        "az.plot_trace(idata, var_names=['beta6'])\n",
        "plt.show()\n",
        "\n",
        "az.plot_trace(idata, var_names=['sigma2_u'])\n",
        "plt.show()\n",
        "\n",
        "az.plot_trace(idata, var_names=['sigma2_v'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nC1Yh881M9G"
      },
      "outputs": [],
      "source": [
        "samples = fit.extract(permuted=True)\n",
        "new_samples = {}\n",
        "\n",
        "\n",
        "for key, value in samples.items():\n",
        "    if len(value.shape) > 1:\n",
        "        for i in range(value.shape[1]):\n",
        "            new_samples[f\"{key}_{i}\"] = value[:, i]\n",
        "    else:\n",
        "        new_samples[key] = value\n",
        "\n",
        "samples.update(new_samples)\n",
        "\n",
        "keys_to_remove = [key for key, value in samples.items() if isinstance(value, np.ndarray) and len(value.shape) > 1]\n",
        "for key in keys_to_remove:\n",
        "    del samples[key]\n",
        "\n",
        "samples_df = pd.DataFrame(samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hDPV39_G1Nmg"
      },
      "outputs": [],
      "source": [
        "samples_df.to_csv('model_results/bayesian_lasso_sample.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "samples_df = pd.read_csv('model_results/bayesian_lasso_sample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "beta1: Mean = -1.1128381086499884e-05, 95% Credible Interval = (-2.2218918466174046e-05, 5.8445346391411605e-08)\n",
            "beta3: Mean = -2.3001572869524977e-06, 95% Credible Interval = (-3.4370202551780097e-06, -1.186770108413141e-06)\n",
            "beta4: Mean = 0.6988388447431003, 95% Credible Interval = (0.6904819125459664, 0.7056114294615995)\n",
            "beta5: Mean = 0.0004671618886451492, 95% Credible Interval = (-0.0009177838598376849, 0.0017800986824795873)\n",
            "beta6: Mean = -1.3445910824247778, 95% Credible Interval = (-1.3571435706877035, -1.3295380809817936)\n"
          ]
        }
      ],
      "source": [
        "betas = ['beta1', 'beta3', 'beta4', 'beta5', 'beta6']\n",
        "\n",
        "results = {}\n",
        "for beta in betas:\n",
        "    mean = samples_df[beta].mean()\n",
        "    ci_lower = np.percentile(samples_df[beta], 2.5)\n",
        "    ci_upper = np.percentile(samples_df[beta], 97.5)\n",
        "    results[beta] = {'mean': mean, '95% CI': (ci_lower, ci_upper)}\n",
        "\n",
        "for beta, vals in results.items():\n",
        "    print(f\"{beta}: Mean = {vals['mean']}, 95% Credible Interval = {vals['95% CI']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(-2.817e-06, -2.2502e-06, -5.667999999999998e-07)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "original_width = -3.77e-06 + 9.53e-07\n",
        "bayesian_lasso_width = -3.4370e-06 + 1.1868e-06\n",
        "\n",
        "original_width, bayesian_lasso_width, original_width - bayesian_lasso_width\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
